@online{twitter_sentiment,
  author = {Rosa Filgueira},
  title = {Twitter Sentiment Analysis},
  year = 2016,
  url = {https://github.com/rosafilgueira/dispel4py_workflows/tree/master/twitter_sentiment},
  urldate = {2016-06-15}
}
@online{cross_correlation,
  author = {Rosa Filgueira},
  title = {Cross-Correlation},
  year = 2016,
  url = {https://github.com/rosafilgueira/dispel4py_workflows/tree/master/tc_cross_correlation},
  urldate = {2016-06-15}
}
@online{internal_extinction,
  author = {Rosa Filgueira},
  title = {Internal Extinction of Galaxies},
  year = 2016,
  url = {https://github.com/rosafilgueira/dispel4py_workflows/tree/master/internal_extinction},
  urldate = {2016-07-04}
}
@article{doi:10.1177/1094342016649766,
author = {Rosa Filguiera and Amrey Krause and Malcolm Atkinson and Iraklis Klampanos and Alexander Moreno},
title = {dispel4py: A Python framework for data-intensive scientific computing},
journal = {The International Journal of High Performance Computing Applications},
volume = {31},
number = {4},
pages = {316-334},
year = {2017},
doi = {10.1177/1094342016649766},

URL = { 
        http://dx.doi.org/10.1177/1094342016649766
    
},
eprint = { 
        http://dx.doi.org/10.1177/1094342016649766
    
}
,
    abstract = { This paper presents dispel4py, a new Python framework for describing abstract stream-based workflows for distributed data-intensive applications. These combine the familiarity of Python programming with the scalability of workflows. Data streaming is used to gain performance, rapid prototyping and applicability to live observations. dispel4py enables scientists to focus on their scientific goals, avoiding distracting details and retaining flexibility over the computing infrastructure they use. The implementation, therefore, has to map dispel4py abstract workflows optimally onto target platforms chosen dynamically. We present four dispel4py mappings: Apache Storm, message-passing interface (MPI), multi-threading and sequential, showing two major benefits: a) smooth transitions from local development on a laptop to scalable execution for production work, and b) scalable enactment on significantly different distributed computing infrastructures. Three application domains are reported and measurements on multiple infrastructures show the optimisations achieved; they have provided demanding real applications and helped us develop effective training. The dispel4py.org is an open-source project to which we invite participation. The effective mapping of dispel4py onto multiple target infrastructures demonstrates exploitation of data-intensive and high-performance computing (HPC) architectures and consistent scalability. }
}

@misc{apache_spark,
  title = {{Apache Spark™; - Lightning-Fast Cluster Computing}},
  howpublished = {\url{http://spark.apache.org/}},
}
@misc{apache_storm,
  title = {{Apache Storm}},
  howpublished = {\url{http://storm.apache.org/} (Jul. 2017)},
}
@misc{MPI_forum,
  title = {{MPI Forum}},
  howpublished = {\url{http://mpi-forum.org/} (Jul. 2017)},
}
@misc{MPI-3.0,
  author={{Message Passing Interface Forum}},
  title={{\textsf{MPI}: A Message-Passing Interface Standard. Version 3.0}},
  note={available at: \url{http://mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf} (Jul. 2017)},
  month={September 21st},
  year={2012},
}
@INPROCEEDINGS{Asterism, 
author={R. Filgueira and R. F. d. Silva and A. Krause and E. Deelman and M. Atkinson}, 
booktitle={2016 Seventh International Workshop on Data-Intensive Computing in the Clouds (DataCloud)}, 
title={Asterism: Pegasus and Dispel4py Hybrid Workflows for Data-Intensive Science}, 
year={2016}, 
pages={1-8}, 
keywords={cloud computing;data handling;public domain software;resource allocation;scheduling;workflow management software;Asterism;Asterism model;DIaaS model;NSF-Chameleon cloud;Pegasus hybrid workflows;computational platforms;computing resources;data distribution across systems;data-intensive applications;data-intensive science;data-intensive workflow composition;data-intensive workflows as a service model;dispel4py hybrid workflows;heterogeneous resources;open source data-intensive framework;parallel stream-based dataflow systems;workflow management systems;Computational modeling;Containers;Data models;Engines;Monitoring;Parallel processing;Storms;Data-Intensive science;deployment and reusability of execution environments;scientific workows;stream-based system}, 
doi={10.1109/DataCloud.2016.004}, 
month={Nov},
}
@article{deelman2015pegasus,
  title={Pegasus, a workflow management system for science automation},
  author={Deelman, Ewa and Vahi, Karan and Juve, Gideon and Rynge, Mats and Callaghan, Scott and Maechling, Philip J and Mayani, Rajiv and Chen, Weiwei and da Silva, Rafael Ferreira and Livny, Miron and others},
  journal={Future Generation Computer Systems},
  volume={46},
  pages={17--35},
  year={2015},
  publisher={Elsevier}
}
@article{ludascher2006scientific,
  title={Scientific workflow management and the {K}epler system},
  author={Lud{\"a}scher, Bertram and Altintas, Ilkay and Berkley, Chad and Higgins, Dan and Jaeger, Efrat and Jones, Matthew and Lee, Edward A and Tao, Jing and Zhao, Yang},
  journal={Concurrency and Computation: Practice and Experience},
  volume={18},
  number={10},
  pages={1039--1065},
  year={2006},
  publisher={Wiley Online Library}
}
@article{teylo2017hybrid,
title = "A hybrid evolutionary algorithm for task scheduling and data assignment of data-intensive scientific workflows on clouds",
journal = "Future Generation Computer Systems",
volume = "76",
number = "",
pages = "1 - 17",
year = "2017",
note = "",
issn = "0167-739X",
doi = "http://dx.doi.org/10.1016/j.future.2017.05.017",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17309883",
author = "Luan Teylo and Ubiratam de Paula and Yuri Frota and Daniel de Oliveira and Lúcia M.A. Drummond",
keywords = "Clouds",
keywords = "Combinatorial optimization",
keywords = "Task scheduling",
keywords = "Data assignment",
keywords = "Hybrid evolutionary algorithm",
abstract = "A growing number of data- and compute-intensive experiments have been modeled as scientific workflows in the last decade. Meanwhile, clouds have emerged as a prominent environment to execute this type of workflows. In this scenario, the investigation of workflow scheduling strategies, aiming at reducing its execution times, became a top priority and a very popular research field. However, few work consider the problem of data file assignment when solving the task scheduling problem. Usually, a workflow is represented by a graph where nodes represent tasks and the scheduling problem consists in allocating tasks to machines to be executed at a predefined time aiming at reducing the makespan of the whole workflow. In this article, we show that the scheduling of scientific workflows can be improved when both task scheduling and the data file assignment problems are treated together. Thus, we propose a new workflow representation, where nodes of the workflow graph represent either tasks or data files, and define the Task Scheduling and Data Assignment Problem (TaSDAP), considering this new model. We formulated this problem as an integer programming problem. Moreover, a hybrid evolutionary algorithm for solving it, named HEA-TaSDAP, is also introduced. To evaluate our approach we conducted two types of experiments: theoretical and practical ones. At first, we compared HEA-TaSDAP with the solutions produced by the mathematical formulation and by other works from related literature. Then, we considered real executions in Amazon EC2 cloud using a real scientific workflow use case (SciPhy for phylogenetic analyses). In all experiments, HEA-TaSDAP outperformed the other classical approaches from the related literature, such as Min–Min and HEFT."
}
@book{hey2009fourth,
  title={The fourth paradigm: data-intensive scientific discovery},
  editor={Hey, Tony and Tansley, Stewart and Tolle, Kristin M and others},
  volume={1},
  year={2009},
  publisher={Microsoft research Redmond, WA}
}
@article{wu2017daliuge,
  title={DALiuGE: A graph execution framework for harnessing the astronomical data deluge},
  author={Wu, Chen and Tobar, Rodrigo and Vinsen, Kevin and Wicenec, Andreas and Pallot, Dave and Lao, Baoqiang and Wang, Ruonan and An, Tao and Boulton, Mark and Cooper, Ian and others},
  journal={Astronomy and Computing},
  volume={20},
  pages={1--15},
  year={2017},
  publisher={Elsevier}
}
@article{couvares2007workflow,
  title={Workflow management in condor},
  author={Couvares, Peter and Kosar, Tevfik and Roy, Alain and Weber, Jeff and Wenger, Kent},
  journal={Workflows for e-Science},
  pages={357--375},
  year={2007},
  publisher={Springer}
}
@article{ATKINSON2017216,
title = "Scientific workflows: Past, present and future",
journal = "Future Generation Computer Systems",
volume = "75",
number = "",
pages = "216 - 227",
year = "2017",
note = "",
issn = "0167-739X",
doi = "http://dx.doi.org/10.1016/j.future.2017.05.041",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17311202",
author = "Malcolm Atkinson and Sandra Gesing and Johan Montagnat and Ian Taylor",
keywords = "Scientific workflows",
keywords = "Scientific methods",
keywords = "Optimisation",
keywords = "Performance",
keywords = "Usability"
}
@article{Kryders_law,
  title = "Kryder’s law",
  author = "Chip Walter",
  journal = "Scientific American",
  year = "2005",
  pages = "32-33"
}
@article{WILDE2011633,
title = "Swift: A language for distributed parallel scripting",
journal = "Parallel Computing",
volume = "37",
number = "9",
pages = "633 - 652",
year = "2011",
note = "Emerging Programming Paradigms for Large-Scale Scientific Computing",
issn = "0167-8191",
doi = "http://dx.doi.org/10.1016/j.parco.2011.05.005",
url = "http://www.sciencedirect.com/science/article/pii/S0167819111000524",
author = "Michael Wilde and Mihael Hategan and Justin M. Wozniak and Ben Clifford and Daniel S. Katz and Ian Foster",
keywords = "Swift",
keywords = "Parallel programming",
keywords = "Scripting",
keywords = "Dataflow"
}
@article{Berthold:2009:KKI:1656274.1656280,
 author = {Berthold, Michael R. and Cebron, Nicolas and Dill, Fabian and Gabriel, Thomas R. and K\"{o}tter, Tobias and Meinl, Thorsten and Ohl, Peter and Thiel, Kilian and Wiswedel, Bernd},
 title = {KNIME - the Konstanz Information Miner: Version 2.0 and Beyond},
 journal = {SIGKDD Explor. Newsl.},
 issue_date = {June 2009},
 volume = {11},
 number = {1},
 month = nov,
 year = {2009},
 issn = {1931-0145},
 pages = {26--31},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/1656274.1656280},
 doi = {10.1145/1656274.1656280},
 acmid = {1656280},
 publisher = {ACM},
 address = {New York, NY, USA},
}
@article{blankenberg2010galaxy,
  title={Galaxy: a web-based genome analysis tool for experimentalists},
  author={Blankenberg, Daniel and Kuster, Gregory Von and Coraor, Nathaniel and Ananda, Guruprasad and Lazarus, Ross and Mangan, Mary and Nekrutenko, Anton and Taylor, James},
  journal={Current protocols in molecular biology},
  pages={19--10},
  publisher={Wiley Online Library}
}
@article{de2008design,
  title={The design and realisation of the myexperiment virtual research environment for social sharing of workflows},
  author={De, David and Carole, Roure and Stevens, Goble Robert},
  year={2008},
  publisher={Citeseer}
}
@Inbook{Mates2011,
author="Mates, Phillip
and Santos, Emanuele
and Freire, Juliana
and Silva, Cl{\'a}udio T.",
editor="Bayard Cushing, Judith
and French, James
and Bowers, Shawn",
title="CrowdLabs: Social Analysis and Visualization for the Sciences",
bookTitle="Scientific and Statistical Database Management: 23rd International Conference, SSDBM 2011, Portland, OR, USA, July 20-22, 2011. Proceedings",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="555--564",
abstract="Managing and understanding the growing volumes of scientific data is one of the most challenging issues scientists face today. As analyses get more complex and large interdisciplinary groups need to work together, knowledge sharing becomes essential to support effective scientific data exploration. While science portals and visualization Web sites have provided a first step towards this goal, by aggregating data from different sources and providing a set of pre-designed analyses and visualizations, they have important limitations. Often, these sites are built manually and are not flexible enough to support the vast heterogeneity of data sources, analysis techniques, data products, and the needs of different user communities. In this paper we describe CrowdLabs, a system that adopts the model used by social Web sites, allowing users to share not only data but also computational pipelines. The shared repository opens up many new opportunities for knowledge sharing and re-use, exposing scientists to tasks that provide examples of sophisticated uses of algorithms they would not have access to otherwise. CrowdLabs combines a set of usable tools and a scalable infrastructure to provide a rich collaborative environment for scientists, taking into account the requirements of computational scientists, such as accessing high-performance computers and manipulating large amounts of data.",
isbn="978-3-642-22351-8",
doi="10.1007/978-3-642-22351-8_38",
url="https://doi.org/10.1007/978-3-642-22351-8_38"
}
@article{GARIJO2017271,
title = "Abstract, link, publish, exploit: An end to end framework for workflow sharing",
journal = "Future Generation Computer Systems",
volume = "75",
number = "",
pages = "271 - 283",
year = "2017",
note = "",
issn = "0167-739X",
doi = "http://dx.doi.org/10.1016/j.future.2017.01.008",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17300274",
author = "Daniel Garijo and Yolanda Gil and Oscar Corcho",
keywords = "Workflow publishing",
keywords = "Workflow consumption",
keywords = "Workflow representation",
keywords = "Provenance",
keywords = "Linked Data",
keywords = "Standards",
keywords = "PROV"
}
@incollection{berriman2007generating,
  title={Generating complex astronomy workflows},
  author={Berriman, G Bruce and Deelman, Ewa and Good, John and Jacob, Joseph C and Katz, Daniel S and Laity, Anastasia C and Prince, Thomas A and Singh, Gurmeet and Su, Mei-Hui},
  booktitle={Workflows for e-Science},
  pages={19--38},
  year={2007},
  publisher={Springer}
}
@article{berriman2010application,
  title={The application of cloud computing to the creation of image mosaics and management of their provenance},
  author={Berriman, G Bruce and Deelman, Ewa and Groth, Paul and Juve, Gideon},
  journal={arXiv preprint arXiv:1006.4860},
  year={2010}
}
@article{maechling2007scec,
  title={SCEC CyberShake workflows—automating probabilistic seismic hazard analysis calculations},
  author={Maechling, Philip and Deelman, Ewa and Zhao, Li and Graves, Robert and Mehta, Gaurang and Gupta, Nitin and Mehringer, John and Kesselman, Carl and Callaghan, Scott and Okaya, David and others},
  journal={Workflows for e-Science},
  pages={143--163},
  year={2007},
  publisher={Springer}
}
@article{aiche2015workflows,
  title={Workflows for automated downstream data analysis and visualization in large-scale computational mass spectrometry},
  author={Aiche, Stephan and Sachsenberg, Timo and Kenar, Erhan and Walzer, Mathias and Wiswedel, Bernd and Kristl, Theresa and Boyles, Matthew and Duschl, Albert and Huber, Christian G and Berthold, Michael R and others},
  journal={Proteomics},
  volume={15},
  number={8},
  pages={1443--1447},
  year={2015},
  publisher={Wiley Online Library}
}
@article{atkinson2012data,
  title={Data-intensive architecture for scientific knowledge discovery},
  author={Atkinson, Malcolm and Liew, Chee Sun and Galea, Michelle and Martin, Paul and Krause, Amrey and Mouat, Adrian and Corcho, Oscar and Snelling, David},
  journal={Distributed and Parallel Databases},
  volume={30},
  number={5-6},
  pages={307--324},
  year={2012},
  publisher={Springer}
}
@article{gwave,
  title="BOSS-LDG: A Novel Computational Framework that Brings Together Blue Waters, Open Science Grid, Shifter and the LIGO Data Grid to Accelerate Gravitational Wave Discovery",
  author="E. A. Huerta and Roland Haas and Edgar Fajardo and Daniel S. Katz and Stuart Anderson and Peter Couvares and Josh Willis and Timothy Bouvet and Jeremy Enos and William T. C. Kramer and Hon Wai Leong and David Wheeler",
  journal="to appear in IEEE eScience Conference",
  year="2017"
}
@article{GUBBI20131645,
title = "Internet of Things (IoT): A vision, architectural elements, and future directions",
journal = "Future Generation Computer Systems",
volume = "29",
number = "7",
pages = "1645 - 1660",
year = "2013",
note = "Including Special sections: Cyber-enabled Distributed Computing for Ubiquitous Cloud and Network Services & Cloud Computing and Scientific Applications — Big Data, Scalable Analytics, and Beyond",
issn = "0167-739X",
doi = "http://dx.doi.org/10.1016/j.future.2013.01.010",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X13000241",
author = "Jayavardhana Gubbi and Rajkumar Buyya and Slaven Marusic and Marimuthu Palaniswami",
keywords = "Internet of Things",
keywords = "Ubiquitous sensing",
keywords = "Cloud computing",
keywords = "Wireless sensor networks",
keywords = "RFID",
keywords = "Smart environments"
}

